{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe5 – Interpretation von Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Beschreibung\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotheken importieren und Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modul Pfad setzen\n",
    "import sys\n",
    "sys.path.append('./module')\n",
    "\n",
    "\n",
    "# Bibliotheken importieren\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Datenvorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgabe 5a)  \n",
    "Lesen Sie den Datensatz Hdma.csv ein und machen Sie sich mit den Daten vertraut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset from csv (use ; as separator)\n",
    "data = pd.read_csv('./data/Hdma.csv', sep=';')\n",
    "# Display first line to test if data was loaded correctly\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataframe size\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz besteht aus 2381 Datenpunkten mit jeweils 13 Merkmalen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Spalten \"pbcr\" und \"self\" enthalten fehlende Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nur in einer Zeile ist \"pbcr\" und \"self\" gleich NaN. Da es nur eine einzige Zeile mit fehlenden Daten gibt, haben wir uns entschieden diese aus dem Datensatz zu entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(2380)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Art der Merkmale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dir` numerisch-kontinuierlich \n",
    "- `hir` numerisch-kontinuierlich\n",
    "- `lvr` numerisch-kontinuierlich\n",
    "- `ccs` kategorisch-ordinal\n",
    "- `mcs` kategorisch-ordinal\n",
    "- `pbcr` kategorisch-nominal\n",
    "- `dmi` kategorisch-nominal\n",
    "- `self` kategorisch-nominal\n",
    "- `single` kategorisch-nominal\n",
    "- `uria` numerisch-kontinuierlich\n",
    "- `condo` kategorisch-nominal\n",
    "- `black` kategorisch-nominal\n",
    "- `deny` kategorisch-nominal\n",
    "\n",
    "\n",
    "Die Zielvariable der Klassifikation ist 'deny' welche angibt ob der Kreditantrag abgelehnt wurde. Es soll bestimmt werden welche Merkmale besonderen Einfluss auf diese haben. Im Speziellen soll bestimmt werden, ob es eine rassistische Diskriminierung gibt. Dafür muss das Merkmal 'black' betrachtet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='deny',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of denials in the dataset\n",
    "data['deny'].value_counts()[1] / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkenntnis: \"Imbalanced Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = ['pbcr', 'dmi', 'self', 'single', 'condo', 'black', 'deny']\n",
    "labelencoder = LabelEncoder()\n",
    "data[nominal_features] = data[nominal_features].apply(labelencoder.fit_transform)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['dir', 'hir', 'lvr']\n",
    "for feature in continuous_features:\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    sns.boxplot(data[feature])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = data[data[\"dir\"]>2]\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(outliers.index, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "sns.heatmap(correlation_matrix,vmin=-1,vmax=1,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays for features and target\n",
    "X = data.drop(\"deny\", axis=1)\n",
    "y = data[\"deny\"]\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "# Create 80/20 train val split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Print resulting dataset sizes\n",
    "print(\"Shape X_train\", X_train.shape)\n",
    "print(\"Shape y_train\", y_train.shape)\n",
    "print(\"Shape X_test\", X_test.shape)\n",
    "print(\"Shape y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistische Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skalieren der Daten für die logistische Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StandardScaler to transform data to zero mean and unit variance\n",
    "sc = StandardScaler()\n",
    "# Fit and transform on training data\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "# Only apply transformation to test data\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistische Regression.\n",
    "\n",
    "`class_weight = 'balanced'` sollte gesetzt werden, da es sich hierbei um einen unbalancierten Datensatz handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lregression = LogisticRegression(solver='lbfgs', class_weight = 'balanced')\n",
    "classifier_lregression.fit(X_train_scaled, y_train)\n",
    "print(f1_score(y_train, classifier_lregression.predict(X_train_scaled)))\n",
    "print(f1_score(y_test, classifier_lregression.predict(X_test_scaled)))\n",
    "print(f1_score(y_train, np.zeros_like(y_train)))\n",
    "print(f1_score(y_test, np.zeros_like(y_test)))\n",
    "\n",
    "print(balanced_accuracy_score(y_test, classifier_lregression.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(data.columns.to_list(), classifier_lregression.coef_.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich verschiedener Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanziieren der genannten Klassifikatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dtree = DecisionTreeClassifier(criterion = 'entropy')\n",
    "classifier_rforest = RandomForestClassifier(n_estimators = 10, random_state=0)\n",
    "classifier_adaboost = AdaBoostClassifier()\n",
    "classifier_nb = ComplementNB() #particularly suited for imbalanced data sets\n",
    "classifier_svm = LinearSVC(max_iter = 10000)\n",
    "\n",
    "classifiers = [classifier_dtree, classifier_rforest, classifier_adaboost, classifier_nb, classifier_svm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainieren der Klassifikatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vergleich der Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den folgenden Zellen wird ein Vergleich der Feature Importances der einzelnen Klassifikatoren durchgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Feature Importance, Koffizienten und _log_ der Wahrscheinlichkeit eines Features einer Klasse sind nicht direkt vergleichbar. Das liegt daran, dass sie unterschiedliche Aussagen treffen:\n",
    "\n",
    "- Feature Importance\n",
    "  - Attribut `feature_importances_` in `DecisionTreeClassifier`, `RandomForestClassifier` und `AdaBoostClassifier`)\n",
    "  - Basiert darauf, wie sehr ein Attribut dazu beiträgt, den sog. \"Information Gain\" in einem Knoten eines Entscheidungsbaums zu erhöhen bzw. die Entropie der Daten in dessen Kind-Knoten zu verringern. Bei Random Forest wird der durchschnitt über alle Entscheidungsbäume für jedes Attribut berechnet. \n",
    "\n",
    "\n",
    "- Koffizienten\n",
    "  - Attribut `coef_` in `LogisticRegression` und `LinearSVC`\n",
    "  - Die Koeffizienten, die bei der Logistischen Regression bzw. beim Trainieren einer Linearen SVM gelernt für die einzelnen Merkmale gelernt wurden.\n",
    "\n",
    "\n",
    "- _log_ der Wahrscheinlichkeit eines Features einer Klasse\n",
    "  - Attribut `feature_log_prob_` in `ComplementNB`\n",
    "  - \n",
    "  \n",
    "Aufgrund dieser Informationen ist lediglich die Reihenfolge der Attribute nach ihrer Wichtigkeit im jeweiligen Klassifikator vergleichbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Method to sort the feature weightings and zip them with the feature names\n",
    "def zip_and_sort(feature_weightings):\n",
    "    for feature, weight in sorted(zip(feature_names, feature_weightings), key=lambda x: abs(x[1]), reverse = True):\n",
    "        print('{:8s}{:.2f}'.format(feature, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sorted feature weightings for every classifier\n",
    "for feature_weightings in [classifier_lregression.coef_[0],\n",
    "                          classifier_dtree.feature_importances_,\n",
    "                          classifier_rforest.feature_importances_,\n",
    "                          classifier_adaboost.feature_importances_,\n",
    "                          classifier_nb.feature_log_prob_[1],\n",
    "                          classifier_svm.coef_[0]]:\n",
    "    zip_and_sort(feature_weightings)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vorhersage im Test-Datensatz mithilfe der Klassifikatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'Most Common Class'\n",
    "score = balanced_accuracy_score(y_test, np.zeros_like(y_test))\n",
    "print('{:25s}{:.2f}\\n'.format(class_name, score))\n",
    "\n",
    "class_name = type(classifier_lregression).__name__\n",
    "score = balanced_accuracy_score(y_test, classifier_lregression.predict(X_test_scaled))\n",
    "print('{:25s}{:.2f}\\n'.format(class_name, score))\n",
    "\n",
    "for classifier in classifiers:\n",
    "    class_name = type(classifier).__name__\n",
    "    score = balanced_accuracy_score(y_test, classifier.predict(X_test))\n",
    "    print('{:25s}{:.2f}'.format(class_name, score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
